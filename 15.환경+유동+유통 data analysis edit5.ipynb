{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:18:37.399044Z",
     "start_time": "2019-09-05T08:18:13.903882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch as fn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#!pip install dbfread\n",
    "\n",
    "import dbfread\n",
    "\n",
    "#!pip install pandas_profiling\n",
    "import pandas_profiling as pp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from matplotlib import font_manager, rc\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from math import sin,cos,sqrt,atan2,radians \n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import skew\n",
    "\n",
    "import requests\n",
    "import logging\n",
    "import time\n",
    "import googlemaps\n",
    "import reverse_geocoder\n",
    "import pprint\n",
    "import folium\n",
    "import zipfile\n",
    "import json\n",
    "#%matplotlib.inline\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False # 마이너스 기호도 표시\n",
    "\n",
    "# 한글 깨짐 방지 목적 #\n",
    "font_name = font_manager.FontProperties(fname = 'c:/Windows/Fonts/malgun.ttf').get_name()\n",
    "rc('font',family = font_name)\n",
    "\n",
    "## 맥\n",
    "# rc('font', family='/Library/Fonts/AppleGothic.ttf')\n",
    "\n",
    "\n",
    "# 만약 plotly가 설치 되지 않았을 경우 하단의 코드를 실행할 것 #\n",
    "#!pip install plotly\n",
    "import plotly\n",
    "#!pip install cufflinks\n",
    "#import plotly.express as px\n",
    "# Cufflinks wrapper on plotly\n",
    "import cufflinks as cf\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import iplot\n",
    "from plotly.offline import init_notebook_mode, plot,iplot\n",
    "\n",
    "init_notebook_mode(connected = True)\n",
    "cf.go_offline()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') # 경고 메시지를 숨길 때"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:18:55.794541Z",
     "start_time": "2019-09-05T08:18:37.401043Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('가공데이터/merge_유통_유동_환경_소상공인_edit1.csv')\n",
    "df = df.iloc[:,1:]\n",
    "df['date'] = pd.to_datetime(df['date'],format = '%Y-%m-%d')\n",
    "\n",
    "df_revised = pd.read_csv('가공데이터/merge_유통_유동_환경_소상공인_edit2.csv')\n",
    "df_revised = df_revised.iloc[:,1:]\n",
    "df_revised['date'] = pd.to_datetime(df_revised['date'],format = '%Y-%m-%d')\n",
    "\n",
    "gs_retail = pd.read_csv('가공데이터/GS편의점_종로노원구.csv')\n",
    "gs_retail = gs_retail.iloc[:,1:]\n",
    "\n",
    "tp_revised = pd.read_csv('가공데이터/유동_edit1.csv')\n",
    "tp_revised = tp_revised.iloc[:,1:]\n",
    "tp_revised = tp_revised.drop(['STD_YM','STD_YMD','HDONG_CD'],axis=1)\n",
    "tp_revised['date'] = pd.to_datetime(tp_revised['date'],format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'year', 'quarter', 'month', 'weekday', 'day', 'district',\n",
       "       'p10_most_freq_day', 'p10_mean_day', 'p10_25per', 'p10_median_day',\n",
       "       'p10_75per', 'p25_most_freq_day', 'p25_mean_day', 'p25_25per',\n",
       "       'p25_median_day', 'p25_75per', 'humi_mean_day', 'humi_median_day',\n",
       "       'humi_25per', 'humi_75per', 'temp_mean_day', 'temp_median_day',\n",
       "       'temp_25per', 'temp_75per', 'noise_mean_day', 'noise_median_day',\n",
       "       'dis_index_most_freq2', 'MAN_0004', 'MAN_0509', 'MAN_1014', 'MAN_1519',\n",
       "       'MAN_2024', 'MAN_2529', 'MAN_3034', 'MAN_3539', 'MAN_4044', 'MAN_4549',\n",
       "       'MAN_5054', 'MAN_5559', 'MAN_6064', 'MAN_6569', 'MAN_70U', 'WMAN_0004',\n",
       "       'WMAN_0509', 'WMAN_1014', 'WMAN_1519', 'WMAN_2024', 'WMAN_2529',\n",
       "       'WMAN_3034', 'WMAN_3539', 'WMAN_4044', 'WMAN_4549', 'WMAN_5054',\n",
       "       'WMAN_5559', 'WMAN_6064', 'WMAN_6569', 'WMAN_70U', 'SGNG_NM', 'values',\n",
       "       'LENGTH', 'AREA', '10_P', '20_P', '30_P', '40_P', '50_P', '60_P',\n",
       "       '70_P', '80_P', 'AMT_IND_10', 'AMT_IND_20', 'AMT_IND_30', 'AMT_IND_40',\n",
       "       'AMT_IND_50', 'AMT_IND_60', 'AMT_IND_70', 'AMT_IND_80', 'tp_method1',\n",
       "       'cri', 'gs_num', 'min_gs', 'max_gs', 'median_gs', 'gsindex1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:18:56.174519Z",
     "start_time": "2019-09-05T08:18:55.796529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STD_YYYY</th>\n",
       "      <th>HDONG_CD</th>\n",
       "      <th>HDONG_NM</th>\n",
       "      <th>SIDO_CD</th>\n",
       "      <th>SIDO_NM</th>\n",
       "      <th>SGNG_CD</th>\n",
       "      <th>SGNG_NM</th>\n",
       "      <th>AREA</th>\n",
       "      <th>LENGTH</th>\n",
       "      <th>X_COORD</th>\n",
       "      <th>Y_COORD</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>1111051500</td>\n",
       "      <td>청운효자동</td>\n",
       "      <td>11</td>\n",
       "      <td>서울특별시</td>\n",
       "      <td>11110</td>\n",
       "      <td>종로구</td>\n",
       "      <td>2573175.62</td>\n",
       "      <td>7975.05</td>\n",
       "      <td>126.972694</td>\n",
       "      <td>37.581306</td>\n",
       "      <td>POINT (126.972694 37.581306)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>1111053000</td>\n",
       "      <td>사직동</td>\n",
       "      <td>11</td>\n",
       "      <td>서울특별시</td>\n",
       "      <td>11110</td>\n",
       "      <td>종로구</td>\n",
       "      <td>1128161.02</td>\n",
       "      <td>5498.40</td>\n",
       "      <td>126.970919</td>\n",
       "      <td>37.573408</td>\n",
       "      <td>POINT (126.9709195 37.573408)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>1111054000</td>\n",
       "      <td>삼청동</td>\n",
       "      <td>11</td>\n",
       "      <td>서울특별시</td>\n",
       "      <td>11110</td>\n",
       "      <td>종로구</td>\n",
       "      <td>1478468.25</td>\n",
       "      <td>7377.76</td>\n",
       "      <td>126.984028</td>\n",
       "      <td>37.582083</td>\n",
       "      <td>POINT (126.984028 37.582083)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>1111055000</td>\n",
       "      <td>부암동</td>\n",
       "      <td>11</td>\n",
       "      <td>서울특별시</td>\n",
       "      <td>11110</td>\n",
       "      <td>종로구</td>\n",
       "      <td>2276588.99</td>\n",
       "      <td>8912.71</td>\n",
       "      <td>126.966500</td>\n",
       "      <td>37.589917</td>\n",
       "      <td>POINT (126.9665 37.589917)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>1111056000</td>\n",
       "      <td>평창동</td>\n",
       "      <td>11</td>\n",
       "      <td>서울특별시</td>\n",
       "      <td>11110</td>\n",
       "      <td>종로구</td>\n",
       "      <td>8951336.18</td>\n",
       "      <td>13312.43</td>\n",
       "      <td>126.968972</td>\n",
       "      <td>37.602583</td>\n",
       "      <td>POINT (126.968972 37.602583)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STD_YYYY    HDONG_CD HDONG_NM SIDO_CD SIDO_NM SGNG_CD SGNG_NM        AREA  \\\n",
       "0     2019  1111051500    청운효자동      11   서울특별시   11110     종로구  2573175.62   \n",
       "1     2019  1111053000      사직동      11   서울특별시   11110     종로구  1128161.02   \n",
       "2     2019  1111054000      삼청동      11   서울특별시   11110     종로구  1478468.25   \n",
       "3     2019  1111055000      부암동      11   서울특별시   11110     종로구  2276588.99   \n",
       "4     2019  1111056000      평창동      11   서울특별시   11110     종로구  8951336.18   \n",
       "\n",
       "     LENGTH     X_COORD    Y_COORD                       geometry  \n",
       "0   7975.05  126.972694  37.581306   POINT (126.972694 37.581306)  \n",
       "1   5498.40  126.970919  37.573408  POINT (126.9709195 37.573408)  \n",
       "2   7377.76  126.984028  37.582083   POINT (126.984028 37.582083)  \n",
       "3   8912.71  126.966500  37.589917     POINT (126.9665 37.589917)  \n",
       "4  13312.43  126.968972  37.602583   POINT (126.968972 37.602583)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_visual = gpd.read_file('Rawdata/유동인구데이터/행정동경계파일/종로_노원_행정동.shp',\n",
    "                             encoding = 'euckr')\n",
    "\n",
    "ad = dbfread.DBF('Rawdata/유동인구데이터/행정동경계파일/종로_노원_행정동.dbf')\n",
    "ad = pd.DataFrame(iter(ad))\n",
    "\n",
    "ad['X_COORD'] = ad['X_COORD'].apply(float)\n",
    "ad['Y_COORD'] = ad['Y_COORD'].apply(float)\n",
    "\n",
    "g_info = [Point(i) for i in zip(ad['X_COORD'],ad['Y_COORD'])]\n",
    "\n",
    "geo_ad = gpd.GeoDataFrame(ad,\n",
    "                          crs = {'init' : 'epsg:4326'},\n",
    "                          geometry = g_info\n",
    "                         )\n",
    "geo_ad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of Problem\n",
    "\n",
    "- 환경 데이터, 유동 데이터, 그리고 T시점 이전의 유통지수를 사용하여 동 및 카테고리별 유통 판매 지수를 예측한다.\n",
    "- 이 경우, 해당 문제는 Sequence Prediction에 해당된다.\n",
    "\n",
    "## sequence Prediction Classification\n",
    "\n",
    "- Sequence Prediction은 크게 'One-to-One Model', 'One-to-Many Model', 'Many-to-One model', 'Many-to-Many model'이 있다.\n",
    "- 이 네 가지 유형들 중에서 현재의 문제는 Multiple Input values를 모델이 받아서 single Output을 도출하는 구조이므로 'Many-To-one' model에 속한다.\n",
    "- 우리가 해결할 문제는 Multivariate & Multi-Step Time Series Forecasting Problem임이 자명하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:18:56.208428Z",
     "start_time": "2019-09-05T08:18:56.177512Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구체적인 전처리\n",
    "\n",
    "### 먼저 전처리의 지역 대상은 동으로 한정한다. 왜냐하면 지수 및 모델의 효과가 동을 기준으로 존재하기 때문이다. \n",
    "\n",
    "### 다음에 불필요한 변수들을 제거한다. \n",
    "\n",
    "### 만약 변수가 정수 또는 부동소수라면 Normalization method 또는 Standardization method를 거친다.\n",
    "\n",
    "#### Normalization은 범위를 0과 1 사이에 모든 값들을 Rescaling하는 작업이다. Normalization은 관측치의 최대값과 최솟값을 정확하게 추정할 수 있어야 한다.\n",
    "\n",
    "#### Standardization은 관측치의 평균을 0으로 그리고 분산을 1로 만드는 Rescaling method이다. Standardization은 관측치가 가우시안 분포를 따른다고 전제한다. 다시 말해서, 평균과 표준편차를 정확하게 추정하고 있어야함을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 변수 Handling\n",
    "\n",
    "#### 범주형 변수의 범주는 정수형이 아니다. 가능한 범주가 K개가 있다면 1~k까지의 정수를 부여하는 것이 간단학 쉬어 보인다. 하지만 그 결과 값은 서로에 대해 순서를 매길 수 있기 때문에 범주로서 허용되지 않는다. 몇 가지 대안이 있다.\n",
    "\n",
    "##### One-hot encoding\n",
    "    - 모든 비트의 합은 1 --> 선형 종속성 --> 선형 모델의 고유성 조건 깨짐\n",
    "    \n",
    "##### Dummy Coding\n",
    "    - 표현식에서 k-1개만을 사용해서 자유도를 k에서 k-1로 줄인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:18:56.252312Z",
     "start_time": "2019-09-05T08:18:56.210424Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testset과 Trainset을 분리하여 첫번째 전처리 작업을 진행한다.\n",
    "\n",
    "- 시계열 데이터이므로 CV(Cross Validation)은 적용할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T12:09:20.220771Z",
     "start_time": "2019-09-05T12:09:20.167794Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pre_processing1(data):\n",
    "    \n",
    "    df_copy = data.copy()\n",
    "    \n",
    "    y = []\n",
    "    y2 = []\n",
    "    \n",
    "    for i in np.unique(df_copy['district']):\n",
    "        df2 = df_copy[df_copy['district'] == i]\n",
    "\n",
    "        df2.index = df2['date']\n",
    "        df2.drop(['date','quarter','day','LENGTH','AREA','SGNG_NM','cri',\n",
    "                  '10_P', '20_P', '30_P', '40_P', '50_P', '60_P','district',\n",
    "                  '70_P', '80_P'],\n",
    "                 axis=1,\n",
    "                 inplace=True)\n",
    "        \n",
    "        target = ['values', 'AMT_IND_10', 'AMT_IND_20', 'AMT_IND_30',\n",
    "        'AMT_IND_40', 'AMT_IND_50', 'AMT_IND_60', 'AMT_IND_70', 'AMT_IND_80']\n",
    "        \n",
    "        x = df2.loc[:,~(df2.columns.isin(target))]\n",
    "        x_t = df2.loc[:,(df2.columns.isin(target))]\n",
    "        \n",
    "        df2['year'] = df2['year'].astype('str')\n",
    "        df2['month'] = df2['month'].astype('str')\n",
    "\n",
    "        for i in x.columns:\n",
    "            if ((x[i].dtypes == 'int')|(x[i].dtypes == 'float')):\n",
    "                if ((skew(x[i]) > -2) & (skew(x[i]) < 2)):\n",
    "                    x[i] = x[i]\n",
    "                else:\n",
    "                    x[i] = np.log(x[i])\n",
    "                    if ((skew(x[i]) > -2) & (skew(x[i]) < 2)):\n",
    "                        x[i] = np.exp(x[i])\n",
    "                        x[i] = np.sqrt(x[i])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "        x2 = x.loc[:,(x.dtypes == 'int')|(x.dtypes == 'float')]\n",
    "        normalized_x2 = pd.DataFrame((x2 - x2.mean())/x2.std())\n",
    "        #normalized_x2.rename(x2.columns,inplace=True)\n",
    "        #normalized_x2.index = df2.index\n",
    "\n",
    "        cate = x.loc[:,x.dtypes == 'object'].columns\n",
    "        df3 = pd.get_dummies(x.loc[:,cate])\n",
    "        df2 = pd.concat([normalized_x2,df3],axis=1)\n",
    "        df2 = df2.loc[:,~(df2.columns.isin(cate))]\n",
    "        df_final = pd.concat([df2,x_t],axis=1)\n",
    "        y.append(df_final)\n",
    "        #y2= pd.concat(y[0:len(y)])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T12:09:37.392110Z",
     "start_time": "2019-09-05T12:09:32.195882Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = pre_processing1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T12:09:40.603395Z",
     "start_time": "2019-09-05T12:09:40.580460Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.unique(df['district']))\n",
    "print(len(np.unique(df['district'])))\n",
    "print(len(y))\n",
    "print(len(y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Sequence into Supervised Problem format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T12:10:07.648481Z",
     "start_time": "2019-09-05T12:10:07.636515Z"
    }
   },
   "outputs": [],
   "source": [
    "target = ['values','AMT_IND_10', 'AMT_IND_20', 'AMT_IND_30',\n",
    "        'AMT_IND_40', 'AMT_IND_50', 'AMT_IND_60', 'AMT_IND_70', 'AMT_IND_80']\n",
    "x_var = y[0].loc[:,~(y[0].columns.isin(target))].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T12:31:42.588792Z",
     "start_time": "2019-09-05T12:31:42.575823Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_processing2(data,input_steps,output_steps,var):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    data = data.reset_index()\n",
    "    data = data.dropna(axis='columns')\n",
    "       \n",
    "    for i in range(len(data)):\n",
    "        end_ix = i + input_steps\n",
    "        output_ix = end_ix + output_steps -1\n",
    "        \n",
    "        if (output_ix > len(data)-6):\n",
    "            break\n",
    "            \n",
    "        x_seq = data.loc[i:end_ix-1,:]\n",
    "        y_seq = data.loc[end_ix:output_ix,var]\n",
    "        x_seq = x_seq.iloc[:,2:]\n",
    "     #   y_seq = y_seq.iloc[:,0:]\n",
    "        \n",
    "        x_seq = x_seq.values\n",
    "        y_seq= y_seq.values\n",
    "        \n",
    "        x_seq = x_seq.reshape(x_seq.shape)\n",
    "#        y_seq = y_seq.values\n",
    "        y_seq = y_seq.reshape(y_seq.shape)\n",
    "        x.append(x_seq)\n",
    "        y.append(y_seq)\n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T12:31:57.307427Z",
     "start_time": "2019-09-05T12:31:56.781082Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_steps = 7\n",
    "output_steps = 7\n",
    "var = target[0]\n",
    "trainx,trainy = pre_processing2(y[0],input_steps,output_steps,var)\n",
    "trainy = np.array([ab.reshape(1,7).tolist() for ab in trainy]).reshape((-1,7))\n",
    "print(trainx.shape)\n",
    "print(trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T12:10:48.526184Z",
     "start_time": "2019-09-05T12:10:48.491267Z"
    }
   },
   "outputs": [],
   "source": [
    "testx,testy = pre_processing2(y2[0],input_steps,output_steps)\n",
    "testx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "\n",
    "## LSTM State Management\n",
    "\n",
    "### The Efficiency of learning : 업데이트 전에 얼마만큼의 샘플들을 학습하여야 하는가?\n",
    "\n",
    "### LSTM 입력층은 3차원이어야 한다.\n",
    "- 3차원 구성 : [samples, time steps, features]\n",
    "\n",
    "### The Speed of Learning : 가중치들은 얼마만큼의 업데이트 주기를 가지는가?\n",
    "\n",
    "### LSTM 내부 상태가 얼마나 자주 reset되어야 하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T12:35:22.847918Z",
     "start_time": "2019-09-05T12:35:22.831001Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_lstm(var):\n",
    "    \n",
    "    plate1,plate2 = [], []\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        input_steps = 7\n",
    "        output_steps = 7\n",
    "        \n",
    "        trainx,trainy = pre_processing2(y[i],input_steps,output_steps,var)\n",
    "      #  testx,testy = pre_processing2(y2[i],input_steps,output_steps)\n",
    "\n",
    "        trainy = np.array([ab.reshape(1,7).tolist() for ab in trainy]).reshape((-1,7))\n",
    "      #  testy = np.array([ab.reshape(1,7).tolist() for ab in testy]).reshape((-1,7))\n",
    "\n",
    "        n_features = trainx.shape[2]\n",
    "\n",
    "        # Define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(150,\n",
    "                        activation='relu',\n",
    "                       return_sequences = True,\n",
    "                        input_shape=(input_steps,n_features)))\n",
    "        model.add(LSTM(150,\n",
    "                        activation='relu'))\n",
    "        model.add(Dense(output_steps))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(optimizer = 'adam', loss = 'mse',metrics = ['accuracy'])\n",
    "\n",
    "        # fit model\n",
    "        fit_lstm = model.fit(trainx,\n",
    "                             trainy,\n",
    "                             shuffle = False,\n",
    "                             epochs=100,\n",
    "                             verbose=1,\n",
    "                             validation_split = 0.2)\n",
    "        \n",
    "        print(fit_lstm.history['loss'])\n",
    "        print(fit_lstm.history['acc'])\n",
    "        print(fit_lstm.history['val_loss'])\n",
    "        print(fit_lstm.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T13:04:14.662609Z",
     "start_time": "2019-09-05T12:35:33.924293Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_lstm('values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lstm(target[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lstm(target[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lstm(target[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lstm(target[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lstm(target[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lstm(target[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lstm(target[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lstm(target[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
